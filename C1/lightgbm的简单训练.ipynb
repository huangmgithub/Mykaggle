{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting lightgbm\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ba/24/2f83a1008c8add8cd9da03163f911be6b555eb2b9166b5ab74e1ad63ff40/lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: wheel in f:\\anaconda3\\lib\\site-packages (from lightgbm) (0.34.2)\n",
      "Requirement already satisfied: scipy in f:\\anaconda3\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: numpy in f:\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in f:\\anaconda3\\lib\\site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in f:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.14.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直接使用lightgbm库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3\n",
      "0  5.1  3.5  1.4  0.2\n",
      "1  4.9  3.0  1.4  0.2\n",
      "2  4.7  3.2  1.3  0.2\n",
      "3  4.6  3.1  1.5  0.2\n",
      "4  5.0  3.6  1.4  0.2\n",
      "   0\n",
      "0  0\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "   sepal_l  sepal_w  petal_l  petal_w\n",
      "0      5.1      3.5      1.4      0.2\n",
      "1      4.9      3.0      1.4      0.2\n",
      "2      4.7      3.2      1.3      0.2\n",
      "3      4.6      3.1      1.5      0.2\n",
      "4      5.0      3.6      1.4      0.2\n",
      "   label\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# 导入数据\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "label = iris.target\n",
    "print(pd.DataFrame(data).head())\n",
    "print(pd.DataFrame(label).head())\n",
    "\n",
    "data1 = pd.DataFrame(data)\n",
    "data1.columns = ['sepal_l','sepal_w','petal_l','petal_w']\n",
    "print(data1.head())\n",
    "\n",
    "label1 = pd.DataFrame(label)\n",
    "label1.columns = [\"label\"]\n",
    "print(label1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集长度: 105\n",
      "测试集长度: 45\n"
     ]
    }
   ],
   "source": [
    "# 划分数据\n",
    "train_x, test_x, train_y, test_y = train_test_split(data1, label1, test_size=0.3, random_state=42)\n",
    "print(\"训练集长度:\", len(train_x))\n",
    "print(\"测试集长度:\", len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86\n",
      "[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.219973\n",
      "[LightGBM] [Info] Start training from score -1.043042\n",
      "[LightGBM] [Info] Start training from score -1.043042\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttraining's multi_error: 0.0666667\tvalid_1's multi_error: 0\n",
      "[[0.1041203  0.70792766 0.18795204]\n",
      " [0.77577839 0.11363916 0.11058245]\n",
      " [0.09406761 0.11820335 0.78772904]\n",
      " [0.11113565 0.65771512 0.23114923]\n",
      " [0.10122466 0.68823982 0.21053553]]\n",
      "test result: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "test precision: 1.0\n",
      "test recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 转换数据格式\n",
    "train_data = lgb.Dataset(train_x, train_y)\n",
    "test_data = lgb.Dataset(test_x, test_y)\n",
    "\n",
    "# 设置参数\n",
    "lgb_params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"verbose\": 1 , # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "    \"num_class\":3 #lightgbm.basic.LightGBMError: b'Number of classes should be specified and greater than 1 for multiclass training'\n",
    "\n",
    "}\n",
    "\n",
    "# 模型训练\n",
    "clf = lgb.train(lgb_params, train_data,num_boost_round=10,\n",
    "               valid_sets=[train_data, test_data],\n",
    "               verbose_eval=10)\n",
    "\n",
    "# 模型预测\n",
    "test_pre = clf.predict(test_x, num_iteration=clf.best_iteration)\n",
    "print(test_pre[:5])\n",
    "\n",
    "# 选择最大概率的列\n",
    "test_pre_1 = np.asarray([np.argmax(row) for row in test_pre])\n",
    "print(\"test result:\", test_pre_1)\n",
    "\n",
    "# 模型评估\n",
    "print('test precision:',precision_score(test_y, test_pre_1, average='macro')) \n",
    "print('test recall:',recall_score(test_y, test_pre_1, average='macro'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn 接口形式使用lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "test precision： 1.0\n",
      "test recall： 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "F:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "    \"learning_rate\":0.1,\n",
    "    \"max_bin\":150,\n",
    "    \"num_leaves\":32,\n",
    "    \"max_depth\":11,\n",
    "    \"objective\":\"multiclass\",\n",
    "    \"n_estimators\":300\n",
    "}\n",
    "\n",
    "model = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# 预测\n",
    "test_pre_2 = model.predict(test_x)\n",
    "print(test_pre_2)\n",
    "# 模型评估\n",
    "print('test precision：',precision_score(test_y, test_pre_2, average='macro')) \n",
    "print('test recall：',recall_score(test_y, test_pre_2, average='macro'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. lgb.train中正则化参数为\"lambda_l1\", \"lambda_l1\"，sklearn中则为'reg_alpha', 'reg_lambda'。\n",
    "2. 多分类时lgb.train除了'objective':'multiclass',还要指定\"num_class\":5，而sklearn接口只需要指定'objective':'multiclass'。\n",
    "3. 迭代次数在sklearn中是'n_estimators':20，在初始化模型时指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
