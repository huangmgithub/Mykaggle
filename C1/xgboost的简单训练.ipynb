{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting xgboost\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/97/ef/05245964011e4fc5aa0d86e2285a41de122ee1c30d69df05ecfd594bd608/xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: scipy in f:\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in f:\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from xgboost) (1.18.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_l  sepal_w  petal_l  petal_w\n",
      "0      5.1      3.5      1.4      0.2\n",
      "1      4.9      3.0      1.4      0.2\n",
      "2      4.7      3.2      1.3      0.2\n",
      "3      4.6      3.1      1.5      0.2\n",
      "4      5.0      3.6      1.4      0.2\n",
      "   label\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# 评价\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# 导入数据\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "label = iris.target\n",
    "\n",
    "data1 = pd.DataFrame(data)\n",
    "# 花萼长宽花瓣长宽\n",
    "data1.columns = [\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]\n",
    "print(data1.head())\n",
    "label1 = pd.DataFrame(label)\n",
    "label1.columns = [\"label\"]\n",
    "print(label1.head())\n",
    "label1.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集长度 105\n",
      "测试集长度 45\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集\n",
    "train_x, test_x, train_y, test_y = train_test_split(data1.values,label1.values,test_size=0.3, random_state=42)\n",
    "print(\"训练集长度\",len(train_x))\n",
    "print(\"测试集长度\",len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直接使用xgboost库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[0.00650657 0.96226174 0.03123167]\n",
      " [0.970643   0.02533228 0.00402478]\n",
      " [0.0033913  0.00692109 0.9896876 ]\n",
      " [0.00654362 0.9677424  0.02571394]\n",
      " [0.00615641 0.9104776  0.083366  ]]\n",
      "test result: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "test precision: 1.0\n",
      "test recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 转换为DMatrix数据格式\n",
    "test_data = xgb.DMatrix(test_x, label=test_y)\n",
    "\n",
    "# 设置参数\n",
    "# multi: softmax是使用softmax后产生的分类结果，而multi: softprob输出的是概率矩阵\n",
    "\n",
    "# 参数\n",
    "xgb_params = {\n",
    "    \"eta\": 0.3, # 学习率\n",
    "    \"silent\": True, # 输出运动讯息\n",
    "    \"objective\": \"multi:softprob\", # 使用多分类生成概率矩阵格式“multi：softprob”\n",
    "    \"num_class\": 3, # 类别数量\n",
    "    \"max_depth\": 3, # 深度\n",
    "}\n",
    "\n",
    "num_round = 20 # 轮数\n",
    "\n",
    "# 模型训练\n",
    "model = xgb.train(xgb_params, xgb.DMatrix(train_x, label=train_y), num_round)\n",
    "# 模型预测\n",
    "test_pre = model.predict(test_data)\n",
    "\n",
    "print(test_pre[:5])\n",
    "\n",
    "# 选择最大概率的列\n",
    "test_pre_1 = np.asarray([np.argmax(row) for row in test_pre])\n",
    "print(\"test result:\", test_pre_1)\n",
    "\n",
    "# 模型评估\n",
    "print(\"test precision:\", precision_score(test_y, test_pre_1, average=\"macro\"))\n",
    "print(\"test recall:\", recall_score(test_y, test_pre_1, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn接口形式使用Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_esimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:02:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "test precision: 1.0\n",
      "test recall: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    learning_rate=0.01, # 学习率\n",
    "    n_esimators=3000, # 步长\n",
    "    max_depth=4, # 深度\n",
    "    objective=\"binary:logistic\",# 二分类 逻辑回归\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# 预测结果\n",
    "test_pre_2 = model.predict(test_x)\n",
    "print(test_pre_2)\n",
    "\n",
    "# 模型评估\n",
    "print(\"test precision:\", precision_score(test_y, test_pre_2, average=\"macro\"))\n",
    "print(\"test recall:\", recall_score(test_y, test_pre_2, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_env]",
   "language": "python",
   "name": "conda-env-tensorflow_env-py"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
