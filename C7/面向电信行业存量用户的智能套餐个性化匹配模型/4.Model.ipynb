{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4063ffc9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-16T17:14:27.646837Z",
     "iopub.status.busy": "2022-05-16T17:14:27.646450Z",
     "iopub.status.idle": "2022-05-16T17:14:27.677927Z",
     "shell.execute_reply": "2022-05-16T17:14:27.677209Z"
    },
    "papermill": {
     "duration": 0.043944,
     "end_time": "2022-05-16T17:14:27.680300",
     "exception": false,
     "start_time": "2022-05-16T17:14:27.636356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/notebook93c5abe0c4/__results__.html\n",
      "/kaggle/input/notebook93c5abe0c4/__notebook__.ipynb\n",
      "/kaggle/input/notebook93c5abe0c4/__output__.json\n",
      "/kaggle/input/notebook93c5abe0c4/custom.css\n",
      "/kaggle/input/notebook93c5abe0c4/stack/train.csv\n",
      "/kaggle/input/notebook93c5abe0c4/stack/test.csv\n",
      "/kaggle/input/ccf-data/ccf_data/test_1.csv\n",
      "/kaggle/input/ccf-data/ccf_data/train_all.csv\n",
      "/kaggle/input/ccf-data/ccf_data/train_2.csv\n",
      "/kaggle/input/ccf-data/ccf_data/test_2.csv\n",
      "/kaggle/input/ccf-data/ccf_data/w2v/1_total_fee.csv\n",
      "/kaggle/input/ccf-data/ccf_data/w2v/4_total_fee.csv\n",
      "/kaggle/input/ccf-data/ccf_data/w2v/2_total_fee.csv\n",
      "/kaggle/input/ccf-data/ccf_data/w2v/3_total_fee.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c63165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T17:14:27.697808Z",
     "iopub.status.busy": "2022-05-16T17:14:27.697476Z",
     "iopub.status.idle": "2022-05-16T17:14:59.142298Z",
     "shell.execute_reply": "2022-05-16T17:14:59.141275Z"
    },
    "papermill": {
     "duration": 31.456389,
     "end_time": "2022-05-16T17:14:59.144988",
     "exception": false,
     "start_time": "2022-05-16T17:14:27.688599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3524: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3524: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并stacking前...\n",
      "374655 160566\n",
      "合并stacking后...\n",
      "374655 160566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3524: DtypeWarning: Columns (4,5,20,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535221\n",
      "535221\n",
      "535221\n",
      "535221\n",
      "535221\n",
      "535221\n",
      "535221\n",
      "535221\n",
      "w2v_features:['1_total_feeW0', '1_total_feeW1', '1_total_feeW2', '1_total_feeW3', '1_total_feeW4', '1_total_feeW5', '1_total_feeW6', '1_total_feeW7', '1_total_feeW8', '1_total_feeW9', '2_total_feeW0', '2_total_feeW1', '2_total_feeW2', '2_total_feeW3', '2_total_feeW4', '2_total_feeW5', '2_total_feeW6', '2_total_feeW7', '2_total_feeW8', '2_total_feeW9', '3_total_feeW0', '3_total_feeW1', '3_total_feeW2', '3_total_feeW3', '3_total_feeW4', '3_total_feeW5', '3_total_feeW6', '3_total_feeW7', '3_total_feeW8', '3_total_feeW9', '4_total_feeW0', '4_total_feeW1', '4_total_feeW2', '4_total_feeW3', '4_total_feeW4', '4_total_feeW5', '4_total_feeW6', '4_total_feeW7', '4_total_feeW8', '4_total_feeW9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "path = \"/kaggle/input/\"\n",
    "\n",
    "data_path = path + \"ccf-data/ccf_data/\"\n",
    "w2v_path = path + \"ccf-data/ccf_data/w2v/\"\n",
    "stack_path = path + \"notebook93c5abe0c4/stack/\"\n",
    "\n",
    "# 原始数据\n",
    "train = pd.read_csv(data_path + \"train_2.csv\")\n",
    "test = pd.read_csv(data_path + \"test_2.csv\")\n",
    "print(\"合并stacking前...\")\n",
    "print(len(train), len(test))\n",
    "\n",
    "# stacking特征\n",
    "train_stacking = pd.read_csv(stack_path + \"train.csv\")\n",
    "test_stacking = pd.read_csv(stack_path + \"test.csv\")\n",
    "\n",
    "# 合并\n",
    "train = train.merge(train_stacking, \"left\", \"user_id\")\n",
    "test = test.merge(test_stacking, \"left\", \"user_id\")\n",
    "print(\"合并stacking后...\")\n",
    "print(len(train), len(test))\n",
    "\n",
    "train_first = pd.read_csv(data_path + \"train_all.csv\")\n",
    "\n",
    "# data_type==0为复赛训练集和测试集\n",
    "# data_type==1为初赛训练集\n",
    "\n",
    "train[\"data_type\"] = 0\n",
    "test[\"data_type\"] = 0\n",
    "train_first[\"data_type\"] = 1\n",
    "\n",
    "# 拼接\n",
    "data = pd.concat([train, test], ignore_index=True).fillna(0) # 将测试集中current_service填充0\n",
    "train_first = train_first.fillna(0)\n",
    "\n",
    "data[\"label\"] = data.current_service.astype(int)\n",
    "data = data.replace(\"\\\\N\", 0)\n",
    "train_first = train_first.replace(\"\\\\N\", 0)\n",
    "data[\"gender\"] = data.gender.astype(int)\n",
    "train_first[\"gender\"] = train_first.gender.astype(int)\n",
    "\n",
    "# 初赛训练集没有service_type==3, 因此将复赛中少量的service_type==3的变更为4\n",
    "data.loc[data[\"service_type\"] == 3, \"service_type\"] = 4\n",
    "\n",
    "# 原始类别特征\n",
    "origin_cate_feature = ['service_type', 'complaint_level', 'contract_type', 'gender', 'is_mix_service',\n",
    "                       'is_promise_low_consume',\n",
    "                       'many_over_bill', 'net_service']\n",
    "\n",
    "# 原始数值特征\n",
    "origin_num_feature = ['1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee',\n",
    "                      'age', 'contract_time',\n",
    "                      'former_complaint_fee', 'former_complaint_num',\n",
    "                      'last_month_traffic', 'local_caller_time', 'local_trafffic_month', 'month_traffic',\n",
    "                      'online_time', 'pay_num', 'pay_times', 'service1_caller_time', 'service2_caller_time']\n",
    "\n",
    "# 转换为浮点数\n",
    "for i in origin_num_feature:\n",
    "    data[i] = data[i].astype(float)\n",
    "    train_first[i] = train_first[i].astype(float)\n",
    "\n",
    "# 数据集和词向量特征合并\n",
    "w2v_features = []\n",
    "for col in ['1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee']:\n",
    "    df = pd.read_csv(w2v_path + \"/\" + col + \".csv\")\n",
    "    df = df.drop_duplicates([col]) # 去除重复值\n",
    "    fs = list(df)\n",
    "    fs.remove(col) # 移除原始特征1_total_fee\n",
    "    w2v_features += fs\n",
    "    print(len(data))\n",
    "    data = pd.merge(data, df, on=col, how=\"left\") # 合并\n",
    "    print(len(data))\n",
    "print(\"w2v_features:{}\".format(w2v_features))\n",
    "\n",
    "count_feature_list = []\n",
    "\n",
    "# 新增count特征\n",
    "def feature_count(data, features=[]):\n",
    "    if len(set(features)) != len(features):\n",
    "        print(\"equal feature !!!\")\n",
    "        return data\n",
    "    new_feature = \"count\"\n",
    "    for i in features:\n",
    "        new_feature += \"_\" + i.replace(\"add_\", \"\")\n",
    "    # temp包含features和size特征\n",
    "    temp = data.groupby(features).size().reset_index().rename(columns={0:new_feature})\n",
    "    # 以features合并temp\n",
    "    data = data.merge(temp, \"left\", on=features)\n",
    "    count_feature_list.append(new_feature)\n",
    "    # 包含service_type时，合并train_first的count特征\n",
    "    if \"service_type\" in features:\n",
    "        temp_2 = train_first.groupby(features).size().reset_index().rename(columns={0:\"train_\" + new_feature})\n",
    "        data = data.merge(temp_2, \"left\", on=features)\n",
    "        count_feature_list.append(\"train_\" + new_feature)\n",
    "    return data\n",
    "\n",
    "# 四个月缴费金额\n",
    "data = feature_count(data, ['1_total_fee'])\n",
    "data = feature_count(data, ['2_total_fee'])\n",
    "data = feature_count(data, ['3_total_fee'])\n",
    "data = feature_count(data, ['4_total_fee'])\n",
    "\n",
    "# 历史执行补救费用交费金额\n",
    "data = feature_count(data, ['former_complaint_fee'])\n",
    "\n",
    "# 交费金额\n",
    "data = feature_count(data, ['pay_num'])\n",
    "# 合约时长\n",
    "data = feature_count(data, ['contract_time'])\n",
    "# 上月结转流量\n",
    "data = feature_count(data, ['last_month_traffic'])\n",
    "# 在网时长\n",
    "data = feature_count(data, ['online_time'])\n",
    "\n",
    "# 套餐类型和合约类型与其他缴费相关\n",
    "for i in ['service_type', 'contract_type']:\n",
    "    data = feature_count(data, [i, '1_total_fee'])\n",
    "    data = feature_count(data, [i, '2_total_fee'])\n",
    "    data = feature_count(data, [i, '3_total_fee'])\n",
    "    data = feature_count(data, [i, '4_total_fee'])\n",
    "    # 历史执行补救费用交费金额\t\n",
    "    data = feature_count(data, [i, 'former_complaint_fee'])\n",
    "    \n",
    "    data = feature_count(data, [i, 'pay_num'])\n",
    "    data = feature_count(data, [i, 'contract_time'])\n",
    "    data = feature_count(data, [i, 'last_month_traffic'])\n",
    "    data = feature_count(data, [i, 'online_time'])\n",
    "    \n",
    "# 插值特征\n",
    "diff_feature_list = ['diff_total_fee_1', 'diff_total_fee_2', 'diff_total_fee_3', 'last_month_traffic_rest',\n",
    "                     'rest_traffic_ratio',\n",
    "                     'total_fee_mean', 'total_fee_max', 'total_fee_min', 'total_caller_time', 'service2_caller_ratio',\n",
    "                     'local_caller_ratio',\n",
    "                     'total_month_traffic', 'month_traffic_ratio', 'last_month_traffic_ratio', 'pay_num_1_total_fee',\n",
    "                     '1_total_fee_call_fee', '1_total_fee_call2_fee', '1_total_fee_trfc_fee']\n",
    "\n",
    "# 两个月之间的交费金额差值\n",
    "data['diff_total_fee_1'] = data['1_total_fee'] - data['2_total_fee']\n",
    "data['diff_total_fee_2'] = data['2_total_fee'] - data['3_total_fee']\n",
    "data['diff_total_fee_3'] = data['3_total_fee'] - data['4_total_fee']\n",
    "\n",
    "# 交费金额和当前总出账金额_月的差值\n",
    "data['pay_num_1_total_fee'] = data['pay_num'] - data['1_total_fee']\n",
    "\n",
    "# 流量差值\n",
    "data['last_month_traffic_rest'] = data['month_traffic'] - data['last_month_traffic']\n",
    "data['last_month_traffic_rest'][data['last_month_traffic_rest'] < 0] = 0  # 流量差值小于0的变为0\n",
    "data['rest_traffic_ratio'] = (data['last_month_traffic_rest'] * 15 / 1024) / data['1_total_fee']\n",
    "\n",
    "total_fee = []\n",
    "for i in range(1, 5):\n",
    "    total_fee.append(str(i) + '_total_fee')\n",
    "    \n",
    "# 4个月出账金额均值，最大值，最小值\n",
    "data['total_fee_mean'] = data[total_fee].mean(1)\n",
    "data['total_fee_max'] = data[total_fee].max(1)\n",
    "data['total_fee_min'] = data[total_fee].min(1)\n",
    "\n",
    "# 通话时长\n",
    "data['total_caller_time'] = data['service2_caller_time'] + data['service1_caller_time']\n",
    "data['service2_caller_ratio'] = data['service2_caller_time'] / data['total_caller_time']\n",
    "data['local_caller_ratio'] = data['local_caller_time'] / data['total_caller_time']\n",
    "\n",
    "# 累计流量\n",
    "data['total_month_traffic'] = data['local_trafffic_month'] + data['month_traffic']\n",
    "data['month_traffic_ratio'] = data['month_traffic'] / data['total_month_traffic']\n",
    "data['last_month_traffic_ratio'] = data['last_month_traffic'] / data['total_month_traffic']\n",
    "\n",
    "# 出账费用和套餐外通话时长费用\n",
    "data['1_total_fee_call_fee'] = data['1_total_fee'] - data['service1_caller_time'] * 0.15\n",
    "data['1_total_fee_call2_fee'] = data['1_total_fee'] - data['service2_caller_time'] * 0.15\n",
    "data['1_total_fee_trfc_fee'] = data['1_total_fee'] - (\n",
    "        data['month_traffic'] - 2 * data['last_month_traffic']) * 0.3\n",
    "\n",
    "# 套餐1，出账金额差值\n",
    "data.loc[data.service_type == 1, '1_total_fee_trfc_fee'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956baf3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T17:14:59.169529Z",
     "iopub.status.busy": "2022-05-16T17:14:59.169201Z",
     "iopub.status.idle": "2022-05-16T17:15:00.443534Z",
     "shell.execute_reply": "2022-05-16T17:15:00.442476Z"
    },
    "papermill": {
     "duration": 1.289524,
     "end_time": "2022-05-16T17:15:00.446065",
     "exception": false,
     "start_time": "2022-05-16T17:14:59.156541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 ['service_type', 'complaint_level', 'contract_type', 'gender', 'is_mix_service', 'is_promise_low_consume', 'many_over_bill', 'net_service', '1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee', 'age', 'contract_time', 'former_complaint_fee', 'former_complaint_num', 'last_month_traffic', 'local_caller_time', 'local_trafffic_month', 'month_traffic', 'online_time', 'pay_num', 'pay_times', 'service1_caller_time', 'service2_caller_time', 'count_1_total_fee', 'count_2_total_fee', 'count_3_total_fee', 'count_4_total_fee', 'count_former_complaint_fee', 'count_pay_num', 'count_contract_time', 'count_last_month_traffic', 'count_online_time', 'count_service_type_1_total_fee', 'train_count_service_type_1_total_fee', 'count_service_type_2_total_fee', 'train_count_service_type_2_total_fee', 'count_service_type_3_total_fee', 'train_count_service_type_3_total_fee', 'count_service_type_4_total_fee', 'train_count_service_type_4_total_fee', 'count_service_type_former_complaint_fee', 'train_count_service_type_former_complaint_fee', 'count_service_type_pay_num', 'train_count_service_type_pay_num', 'count_service_type_contract_time', 'train_count_service_type_contract_time', 'count_service_type_last_month_traffic', 'train_count_service_type_last_month_traffic', 'count_service_type_online_time', 'train_count_service_type_online_time', 'count_contract_type_1_total_fee', 'count_contract_type_2_total_fee', 'count_contract_type_3_total_fee', 'count_contract_type_4_total_fee', 'count_contract_type_former_complaint_fee', 'count_contract_type_pay_num', 'count_contract_type_contract_time', 'count_contract_type_last_month_traffic', 'count_contract_type_online_time', 'diff_total_fee_1', 'diff_total_fee_2', 'diff_total_fee_3', 'last_month_traffic_rest', 'rest_traffic_ratio', 'total_fee_mean', 'total_fee_max', 'total_fee_min', 'total_caller_time', 'service2_caller_ratio', 'local_caller_ratio', 'total_month_traffic', 'month_traffic_ratio', 'last_month_traffic_ratio', 'pay_num_1_total_fee', '1_total_fee_call_fee', '1_total_fee_call2_fee', '1_total_fee_trfc_fee', '1_total_feeW0', '1_total_feeW1', '1_total_feeW2', '1_total_feeW3', '1_total_feeW4', '1_total_feeW5', '1_total_feeW6', '1_total_feeW7', '1_total_feeW8', '1_total_feeW9', '2_total_feeW0', '2_total_feeW1', '2_total_feeW2', '2_total_feeW3', '2_total_feeW4', '2_total_feeW5', '2_total_feeW6', '2_total_feeW7', '2_total_feeW8', '2_total_feeW9', '3_total_feeW0', '3_total_feeW1', '3_total_feeW2', '3_total_feeW3', '3_total_feeW4', '3_total_feeW5', '3_total_feeW6', '3_total_feeW7', '3_total_feeW8', '3_total_feeW9', '4_total_feeW0', '4_total_feeW1', '4_total_feeW2', '4_total_feeW3', '4_total_feeW4', '4_total_feeW5', '4_total_feeW6', '4_total_feeW7', '4_total_feeW8', '4_total_feeW9', 'stacking_0', 'stacking_1', 'stacking_2', 'stacking_3', 'stacking_4', 'stacking_5', 'stacking_6', 'stacking_7', 'stacking_8', 'stacking_9', 'stacking_10']\n"
     ]
    }
   ],
   "source": [
    "# 类别特征\n",
    "cate_feature = origin_cate_feature\n",
    "# 数值特征\n",
    "num_feature = origin_num_feature + count_feature_list + diff_feature_list + w2v_features + ['stacking_' + str(i) for i\n",
    "                                                                                            in range(11)]\n",
    "\n",
    "# 变更数据格式\n",
    "for i in cate_feature:\n",
    "    data[i] = data[i].astype('category')\n",
    "for i in num_feature:\n",
    "    data[i] = data[i].astype(float)\n",
    "\n",
    "# 所有特征\n",
    "feature = cate_feature + num_feature\n",
    "print(len(feature), feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe596a14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T17:15:00.473210Z",
     "iopub.status.busy": "2022-05-16T17:15:00.472373Z",
     "iopub.status.idle": "2022-05-16T17:54:38.212169Z",
     "shell.execute_reply": "2022-05-16T17:54:38.211149Z"
    },
    "papermill": {
     "duration": 2377.760157,
     "end_time": "2022-05-16T17:54:38.219117",
     "exception": false,
     "start_time": "2022-05-16T17:15:00.458960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106801\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    boosting_type=\"gbdt\", num_leaves=152, reg_alpha=0, reg_lambda=0.,\n",
    "    max_depth=-1, n_estimators=1000, objective='multiclass', class_weight=\"balanced\",\n",
    "    subsample=0.9, colsample_bytree=0.5, subsample_freq=1,\n",
    "    learning_rate=0.03, random_state=2018, n_jobs=10\n",
    ")\n",
    "# 复赛训练数据\n",
    "lgb_model.fit(data[data.label != 0][feature],data[data.label != 0].label, categorical_feature=cate_feature)\n",
    "\n",
    "result_type1 = pd.DataFrame()\n",
    "\n",
    "# 复赛测试集中service_type==1时的user_id和predict\n",
    "result_type1[\"user_id\"] = data[(data.label == 0) & (data.service_type == 1)][\"user_id\"]\n",
    "result_type1[\"predict\"] = lgb_model.predict(data[(data.label == 0) & (data.service_type == 1)][feature])\n",
    "print(len(result_type1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7621df78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T17:54:38.245706Z",
     "iopub.status.busy": "2022-05-16T17:54:38.245345Z",
     "iopub.status.idle": "2022-05-16T17:54:38.249864Z",
     "shell.execute_reply": "2022-05-16T17:54:38.248994Z"
    },
    "papermill": {
     "duration": 0.020347,
     "end_time": "2022-05-16T17:54:38.251800",
     "exception": false,
     "start_time": "2022-05-16T17:54:38.231453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_marco(pred, labels):\n",
    "    labels = np.argmax(labels.reshape(8, -1), axis=0)\n",
    "    score = f1_score(y_true=labels, y_pred=preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89198249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T17:54:38.278096Z",
     "iopub.status.busy": "2022-05-16T17:54:38.277817Z",
     "iopub.status.idle": "2022-05-16T19:07:54.405435Z",
     "shell.execute_reply": "2022-05-16T19:07:54.404565Z"
    },
    "papermill": {
     "duration": 4396.143686,
     "end_time": "2022-05-16T19:07:54.407859",
     "exception": false,
     "start_time": "2022-05-16T17:54:38.264173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[89950166 99999828 99999825 89950167 99999830 89950168 99999826 99999827]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[99999830 99999828 89950168 89950167 99999826 89950166 99999825 99999827]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[99999826 89950166 99999828 89950167 99999830 89950168 99999827 99999825]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[99999827 99999828 89950166 99999826 89950167 99999830 99999825 89950168]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[89950167 99999827 99999830 89950168 99999826 99999828 89950166 99999825]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160566 90063345    93141\n",
      "89950167    16658\n",
      "89950166    12352\n",
      "90109916     7996\n",
      "99999828     7321\n",
      "90155946     5664\n",
      "99999826     4162\n",
      "99999830     3866\n",
      "99999827     3664\n",
      "89950168     3066\n",
      "99999825     2675\n",
      "999999          1\n",
      "Name: predict, dtype: int64\n",
      "                 user_id   predict\n",
      "374655  013mNJ4xUaAzRLG9  90063345\n",
      "374656  013oEGVd7HIWtvPZ  90063345\n",
      "374657  0156TRH7IzXNh8pj  99999830\n",
      "374658  019EdSRKXsYDvGNM  89950166\n",
      "374659  019SyqXtp24FW5gx  89950167\n"
     ]
    }
   ],
   "source": [
    "# 复赛训练集\n",
    "X = data[(data.label != 0) & (data.label != 999999)][feature].reset_index(drop=True)\n",
    "y = data[(data.label != 0) & (data.label != 999999)].label.reset_index(drop=True)\n",
    "\n",
    "label2current_service = dict(\n",
    "    zip(range(0, len(set(y))), sorted(list(set(y))))\n",
    ")\n",
    "current_service2label = dict(\n",
    "    zip(sorted(list(set(y))), range(0, len(set(y))))\n",
    ")\n",
    "\n",
    "cv_pred = []\n",
    "#5折交叉验证\n",
    "skf = StratifiedKFold(n_splits=5, random_state=20181, shuffle=True)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(index)\n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        boosting_type=\"gbdt\", num_leaves=120, reg_alpha=0, reg_lambda=0.,\n",
    "        max_depth=-1, n_estimators=800, objective='multiclass', class_weight='balanced',\n",
    "        subsample=0.9, colsample_bytree=0.5, subsample_freq=1,\n",
    "        learning_rate=0.03, random_state=2018 + index, n_jobs=10, metric=\"None\", importance_type='gain'\n",
    "    )\n",
    "    # 训练和测试数据\n",
    "    train_x, test_x, train_y, test_y = X.loc[train_index], X.loc[test_index], y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "    # service_type == 4\n",
    "    train_x = train_x[train_x.service_type == 4]\n",
    "    train_y = train_y[(train_x.service_type == 4).index]\n",
    "    test_x = test_x[test_x.service_type == 4]\n",
    "    test_y = test_y[(test_x.service_type == 4).index]\n",
    "    print(test_y.unique())\n",
    "    \n",
    "    eval_set = [(test_x, test_y)]\n",
    "    lgb_model.fit(train_x, train_y, categorical_feature=cate_feature)\n",
    "    # 每次都要预测一下y_test\n",
    "    y_test = lgb_model.predict(data[(data.label == 0) & (data.service_type != 1)][feature])\n",
    "    y_test = pd.Series(y_test).map(current_service2label)\n",
    "    if index == 0:\n",
    "        cv_pred = np.array(y_test).reshape(-1, 1)\n",
    "    else:\n",
    "        cv_pred = np.hstack((cv_pred, np.array(y_test).reshape(-1, 1)))  # 沿着水平方向拼接\n",
    "\n",
    "# cv_pred每一列都是一组预测值，bincount计数得到数量最多的预测值\n",
    "submit = []\n",
    "for line in cv_pred:\n",
    "    submit.append(np.argmax(np.bincount(line))) # 计数\n",
    "result = pd.DataFrame()\n",
    "result['user_id'] = data[(data.label == 0) & (data.service_type != 1)]['user_id']\n",
    "result['predict'] = submit\n",
    "result['predict'] = result['predict'].map(label2current_service)\n",
    "result.loc[result['user_id'] == '4VNcD6kE0sjnAvFX', 'predict'] = 999999\n",
    "result = result.append(result_type1)\n",
    "\n",
    "print(len(result), result.predict.value_counts())\n",
    "print(result.sort_values('user_id').head())\n",
    "\n",
    "output_path = \"/kaggle/working\"\n",
    "result[['user_id', 'predict']].to_csv(\n",
    "    output_path + '/sub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834c6b6",
   "metadata": {
    "papermill": {
     "duration": 0.01668,
     "end_time": "2022-05-16T19:07:54.441854",
     "exception": false,
     "start_time": "2022-05-16T19:07:54.425174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6817.680494,
   "end_time": "2022-05-16T19:07:55.494565",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-16T17:14:17.814071",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
